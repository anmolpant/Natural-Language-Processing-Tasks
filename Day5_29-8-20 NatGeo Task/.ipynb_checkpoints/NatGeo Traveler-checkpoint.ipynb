{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP hands on activity\n",
    "\n",
    "### Anmol Pant\n",
    "### 18BCE0283"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### document extraction and stopword removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_doc(doc):\n",
    "    f = open(doc,\"r\", encoding='utf-8')\n",
    "    data = f.read()\n",
    "    word_tokens = word_tokenize(data)\n",
    "    stop_words = list(set(stopwords.words('english')))\n",
    "    filtered_sentence = []\n",
    "    stopwords_list = []\n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w)\n",
    "        else:\n",
    "            stopwords_list.append(w)\n",
    "    \n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = extract_doc(r\"C:\\Users\\anmol\\Downloads\\natgeo1.txt\")\n",
    "d2 = extract_doc(r\"C:\\Users\\anmol\\Downloads\\natgeo2.txt\")\n",
    "d3 = extract_doc(r\"C:\\Users\\anmol\\Downloads\\natgeo3.txt\")\n",
    "d4 = extract_doc(r\"C:\\Users\\anmol\\Downloads\\natgeo4.txt\")\n",
    "d5 = extract_doc(r\"C:\\Users\\anmol\\Downloads\\sample.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_words = list(set(d1+d2+d3+d4+d5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['server—a',\n",
       " 'meat',\n",
       " ';',\n",
       " 'buy',\n",
       " 'work',\n",
       " 'sailboat',\n",
       " 'confound',\n",
       " 'much.',\n",
       " 'Serampore',\n",
       " 'penny',\n",
       " 'face',\n",
       " 'things',\n",
       " 'big',\n",
       " 'variety.',\n",
       " 'memorable',\n",
       " 'passing',\n",
       " 'Golightly',\n",
       " 'growing',\n",
       " 'Have',\n",
       " 'taught',\n",
       " 'read',\n",
       " 'luxury',\n",
       " 'Ardent',\n",
       " '?',\n",
       " 'hotel',\n",
       " 'cultures',\n",
       " 'thinking',\n",
       " 'privileges',\n",
       " 'binge',\n",
       " 'wanderlust.',\n",
       " 'hidden',\n",
       " 'Yes.',\n",
       " 'crudest',\n",
       " 'irrevocably',\n",
       " 'Hacks',\n",
       " 'abound',\n",
       " 'Not',\n",
       " 'understated',\n",
       " 'institutions—a',\n",
       " 'nightclubs',\n",
       " 'showing',\n",
       " 'me.',\n",
       " 'West',\n",
       " 'somewhere',\n",
       " 'sunglasses',\n",
       " 'champagne',\n",
       " 'though',\n",
       " 'gully',\n",
       " 'Rome',\n",
       " 'escape',\n",
       " 'on…',\n",
       " 'mean',\n",
       " 'suburbs',\n",
       " 'hankering',\n",
       " 'He',\n",
       " 'substantial',\n",
       " 'list',\n",
       " 'Long',\n",
       " 'happy',\n",
       " 'Craig',\n",
       " 'rise',\n",
       " 'home',\n",
       " 'eternally',\n",
       " 'attitudes',\n",
       " 'Reema',\n",
       " 'itinerary',\n",
       " 'They',\n",
       " 'stumble',\n",
       " 'Rio',\n",
       " 'stories',\n",
       " 'close',\n",
       " 'glances',\n",
       " 'Sufi',\n",
       " 'colourful',\n",
       " 'Goutillon',\n",
       " 'music',\n",
       " 'dances',\n",
       " 'drummed',\n",
       " 'need',\n",
       " 'long-term',\n",
       " 'claim',\n",
       " 'contrast',\n",
       " 'faces',\n",
       " 'moving',\n",
       " 'place',\n",
       " 'perfect',\n",
       " 'waged',\n",
       " 'maiden',\n",
       " 'caused',\n",
       " 'cad',\n",
       " 'Member',\n",
       " 'no-nonsense',\n",
       " 'someone',\n",
       " 'Like',\n",
       " 'extolling',\n",
       " 'interesting',\n",
       " 'gates',\n",
       " 'manager',\n",
       " 'Traveller',\n",
       " 'drinking',\n",
       " 'conservatively',\n",
       " 'regular',\n",
       " 'must-haves',\n",
       " 'recalls',\n",
       " 'parts',\n",
       " 'recreational',\n",
       " 'unsentimental',\n",
       " 'Lumpur',\n",
       " 'When',\n",
       " 'obtuse…',\n",
       " 'unending',\n",
       " 'Our',\n",
       " 'unrequited',\n",
       " 'authenticity',\n",
       " 'answer',\n",
       " 'like',\n",
       " 'knowing',\n",
       " 'avowed',\n",
       " 'Last',\n",
       " 'reveals',\n",
       " 'precisely',\n",
       " 'unearthed',\n",
       " 'confines',\n",
       " 'entries',\n",
       " 'divided',\n",
       " 'toasts',\n",
       " 'country',\n",
       " 'Lensman',\n",
       " 'credentials',\n",
       " 'grasp',\n",
       " 'inner',\n",
       " 'drives',\n",
       " 'physical',\n",
       " 'messy',\n",
       " 'One',\n",
       " 'slacking',\n",
       " 'madcap',\n",
       " 'afoot',\n",
       " 'British',\n",
       " 'gathers',\n",
       " 'asked',\n",
       " 'ode',\n",
       " 'entitlement',\n",
       " 'sidewalks',\n",
       " 'choose',\n",
       " 'aesthetes',\n",
       " 'hedonistic',\n",
       " 'directed',\n",
       " 'grappling',\n",
       " 'facilitates',\n",
       " 'glimpse',\n",
       " 'haunts',\n",
       " 'might',\n",
       " 'My',\n",
       " 'York',\n",
       " 'found',\n",
       " 'top',\n",
       " 'standing',\n",
       " 'Besides',\n",
       " 'producing',\n",
       " 'kitchen',\n",
       " 'unexpected',\n",
       " 'marvel',\n",
       " 'National',\n",
       " 'Abhishek',\n",
       " 'philosophers',\n",
       " 'impressed',\n",
       " 'dinner',\n",
       " 'culture',\n",
       " 'surprises',\n",
       " 'air',\n",
       " 'counter',\n",
       " 'Travellers',\n",
       " 'right',\n",
       " 'bistro',\n",
       " 'insights',\n",
       " 'madness',\n",
       " 'Dubrovnik',\n",
       " 'Now—As',\n",
       " 'spikier',\n",
       " 'practising',\n",
       " 'We',\n",
       " 'mockery',\n",
       " 'paramours',\n",
       " 'year-end',\n",
       " 'preach',\n",
       " 'woman—took',\n",
       " 'Antoine',\n",
       " 'gaudy',\n",
       " 'Korea',\n",
       " 'flâneur',\n",
       " 'nooks',\n",
       " 'tastes',\n",
       " 'today',\n",
       " 'fork',\n",
       " 'manors',\n",
       " 'struck',\n",
       " 'debate',\n",
       " 'wink',\n",
       " 'maybe',\n",
       " 'curdle',\n",
       " 'atop',\n",
       " 'Molotov',\n",
       " 'Kaushal',\n",
       " 'bravado',\n",
       " 'After',\n",
       " 'veer',\n",
       " 'affection',\n",
       " 'Of',\n",
       " 'personal',\n",
       " 'predictability',\n",
       " 'window',\n",
       " 'Churchgate',\n",
       " 'Shangri-La',\n",
       " 'love',\n",
       " 'nostalgic',\n",
       " 'eyebrow-cocked',\n",
       " 'magazine',\n",
       " 'spectacle',\n",
       " 'NGTI',\n",
       " 'used',\n",
       " 'kick',\n",
       " 'soon',\n",
       " 'hurt',\n",
       " 'manifold',\n",
       " 'conundrum',\n",
       " 'give',\n",
       " 'retreats',\n",
       " 'wars',\n",
       " 'feeling',\n",
       " 'attempts',\n",
       " 'What',\n",
       " 'urban',\n",
       " 'staple',\n",
       " 'Mark',\n",
       " 'Indian-American',\n",
       " 'Parliament',\n",
       " 'Karkhanis',\n",
       " 'shook',\n",
       " 'beef',\n",
       " 'Left',\n",
       " 'jungle',\n",
       " 'golden',\n",
       " 'featuring',\n",
       " 'issue',\n",
       " 'coverage',\n",
       " 'setting',\n",
       " 'perhaps',\n",
       " 'red',\n",
       " 'stretch',\n",
       " 'Early',\n",
       " 'reason',\n",
       " 'overrated',\n",
       " 'ultra-indulgence',\n",
       " 'study',\n",
       " 'Maldives',\n",
       " 'Iranian',\n",
       " 'day',\n",
       " 'elegant',\n",
       " 'disapproval',\n",
       " 'ill-prepared',\n",
       " 'industrious',\n",
       " 'Alex',\n",
       " 'spent—or',\n",
       " 'navigate',\n",
       " 'Aviv',\n",
       " 'know',\n",
       " 'I',\n",
       " 'usually',\n",
       " 'section',\n",
       " 'sweaty',\n",
       " 'understand',\n",
       " 'Local',\n",
       " 'beeline',\n",
       " 'Tharoor',\n",
       " 'acutely',\n",
       " 'business',\n",
       " 'book',\n",
       " 'indulge',\n",
       " 'narratives',\n",
       " 'offers',\n",
       " 'gourmands',\n",
       " 'special',\n",
       " 'told',\n",
       " 'never',\n",
       " 'precise',\n",
       " 'back',\n",
       " 'reap',\n",
       " 'gluttony',\n",
       " 'ocean',\n",
       " 'former',\n",
       " 'faithfully',\n",
       " 'bus',\n",
       " 'brutal',\n",
       " 'journeys',\n",
       " 'It',\n",
       " 'About',\n",
       " 'predilections',\n",
       " 'typical',\n",
       " 'Finally',\n",
       " 'settle',\n",
       " 'would',\n",
       " 'mouths',\n",
       " 'baklava',\n",
       " 'restaurant',\n",
       " 'night',\n",
       " 'call',\n",
       " 'views',\n",
       " 'modern',\n",
       " 'visit',\n",
       " 'barely',\n",
       " 'prompted',\n",
       " 'Go',\n",
       " 'Wresting',\n",
       " 'Living',\n",
       " 'This',\n",
       " 'subcultures',\n",
       " 'within',\n",
       " 'Shashi',\n",
       " 'picks',\n",
       " 'Prize',\n",
       " 'Train',\n",
       " 'either',\n",
       " 'inevitably',\n",
       " 'rather',\n",
       " 'cities',\n",
       " 'oldest',\n",
       " 'French',\n",
       " 'guide',\n",
       " 'heard',\n",
       " 'emboldened',\n",
       " '10-minute',\n",
       " 'deserve',\n",
       " 'Jazz',\n",
       " 'Turkey.',\n",
       " 'musician',\n",
       " 'khau',\n",
       " 'undercurrents',\n",
       " 'Gupta',\n",
       " 'digs',\n",
       " 'radioactive',\n",
       " 'She',\n",
       " 'elegance',\n",
       " 'south',\n",
       " 'dolmades',\n",
       " 'classical',\n",
       " 'South',\n",
       " 'occasional',\n",
       " 'giggled',\n",
       " 'different',\n",
       " 'biases',\n",
       " 'notice',\n",
       " 'Yards',\n",
       " 'Kala',\n",
       " 'dry',\n",
       " 'immersing',\n",
       " 'gentleman',\n",
       " 'features',\n",
       " 'flits',\n",
       " 'Holly',\n",
       " 'across',\n",
       " 'show',\n",
       " 'filthy',\n",
       " 'got',\n",
       " 'extra',\n",
       " 'baba',\n",
       " 'distillation',\n",
       " 'fairly',\n",
       " 'it.',\n",
       " 'In',\n",
       " 'month',\n",
       " 'baklava—a',\n",
       " 'battles',\n",
       " 'end',\n",
       " 'perusing',\n",
       " 'Bewitching',\n",
       " 'gauche',\n",
       " 'fertile',\n",
       " 'around',\n",
       " 'little',\n",
       " 'Lewis',\n",
       " 'pilgrimage',\n",
       " 'hour',\n",
       " 'pass',\n",
       " 'complicated',\n",
       " 'wonderful',\n",
       " 'ruins',\n",
       " 'went',\n",
       " 'became',\n",
       " 'moniker',\n",
       " 'reading',\n",
       " 'bunch',\n",
       " 'haleem',\n",
       " 'enjoys',\n",
       " 'weekend',\n",
       " 'hosting',\n",
       " 'Janeiro',\n",
       " 'Some',\n",
       " 'appetite',\n",
       " 'besotted',\n",
       " 'take',\n",
       " 'feasts',\n",
       " 'Thomas',\n",
       " 'David',\n",
       " 'House',\n",
       " 'adopted',\n",
       " 'brave',\n",
       " 'profile',\n",
       " 'observations',\n",
       " 'Days',\n",
       " 'For',\n",
       " 'contact',\n",
       " 'venue',\n",
       " 'wish',\n",
       " 'uttering',\n",
       " 'Pariat',\n",
       " 'almost',\n",
       " 'nice',\n",
       " 'paradises',\n",
       " 'mainland',\n",
       " 'wallet',\n",
       " 'Sharma',\n",
       " 'Smart',\n",
       " 'reclusive',\n",
       " 'unwarranted',\n",
       " 'attempting',\n",
       " 'stopped',\n",
       " 'assure',\n",
       " 'Dixit',\n",
       " 'complaints',\n",
       " 'could',\n",
       " 'destined',\n",
       " 'Rhythm',\n",
       " 'compatriot',\n",
       " 'pair',\n",
       " 'infinitely',\n",
       " 'torment',\n",
       " 'befitting',\n",
       " 'tell',\n",
       " 'example',\n",
       " 'America',\n",
       " 'leave',\n",
       " 'sleep',\n",
       " 'Hyderabad',\n",
       " 'cuts',\n",
       " 'unchaperoned',\n",
       " 'writer',\n",
       " 'Janice',\n",
       " 'last',\n",
       " 'finish',\n",
       " 'sample',\n",
       " 'shop',\n",
       " 'least',\n",
       " 'hung',\n",
       " '0',\n",
       " 'pulse',\n",
       " 'followed',\n",
       " 'fill',\n",
       " 'Riviera',\n",
       " 'open-minded',\n",
       " 'turn',\n",
       " 'fielding',\n",
       " 'unlike',\n",
       " 'passes',\n",
       " 'locals',\n",
       " 'Canteen',\n",
       " 'characters',\n",
       " 'Bourdain',\n",
       " 'words',\n",
       " 'habit',\n",
       " 'free',\n",
       " 'decodes',\n",
       " 'castles',\n",
       " 'dull',\n",
       " 'reminisces',\n",
       " 'bit',\n",
       " 'Twain',\n",
       " 'way',\n",
       " 'intertwined',\n",
       " 'tutorial',\n",
       " ':',\n",
       " 'mind',\n",
       " 'stance',\n",
       " 'stand',\n",
       " '#',\n",
       " 'man',\n",
       " 'minimum',\n",
       " 'alleys',\n",
       " 'always',\n",
       " 'sundeck',\n",
       " 'money',\n",
       " 'storied',\n",
       " 'fortnight',\n",
       " 'best',\n",
       " 'backpacking',\n",
       " 'repulsed',\n",
       " 'shade',\n",
       " 'later',\n",
       " 'revealed',\n",
       " 'ways',\n",
       " 'dives',\n",
       " 'café',\n",
       " 'travelling',\n",
       " 'downsizers',\n",
       " 'affordability',\n",
       " 'exotification',\n",
       " 'private',\n",
       " 'Raghu',\n",
       " 'misplaced',\n",
       " 'city',\n",
       " 'rein',\n",
       " 'celebrated',\n",
       " 'look',\n",
       " 'recent',\n",
       " 'declared',\n",
       " 'stench',\n",
       " 'fight',\n",
       " 'yet',\n",
       " 'fuss',\n",
       " 'Shillong',\n",
       " 'precarious',\n",
       " 'worth',\n",
       " 'featured',\n",
       " 'chided',\n",
       " 'BEST',\n",
       " 'sixth',\n",
       " 'wistful',\n",
       " 'Einstein',\n",
       " 'Rajasthan',\n",
       " 'casual',\n",
       " 'injury',\n",
       " 'lived',\n",
       " 'comfortable',\n",
       " 'question',\n",
       " 'Kolkata',\n",
       " 'pow-wow',\n",
       " 'Who',\n",
       " 'Rorschach',\n",
       " 'true',\n",
       " 'sentiments',\n",
       " 'dreamers',\n",
       " 'regret',\n",
       " 'mob',\n",
       " 'Travel',\n",
       " 'pang',\n",
       " 'Turkish',\n",
       " 'worst',\n",
       " 'De',\n",
       " 'August',\n",
       " 'Bengal',\n",
       " 'see',\n",
       " 'rounded',\n",
       " 'financial',\n",
       " 'capital',\n",
       " 'desperately-trying-to-be-hip',\n",
       " 'sings',\n",
       " 'traveller',\n",
       " 'streets',\n",
       " 'dessert',\n",
       " 'Arabian',\n",
       " 'circuitous',\n",
       " 'dishes',\n",
       " 'exclamations',\n",
       " 'astute',\n",
       " 'highways',\n",
       " 'term',\n",
       " 'turbulent',\n",
       " 'showcasing',\n",
       " 'tourists',\n",
       " 'eatery',\n",
       " 'identity',\n",
       " 'tried',\n",
       " 'loafer',\n",
       " 'holidays',\n",
       " 'Banaras',\n",
       " 'often',\n",
       " 'Bring',\n",
       " 'relation',\n",
       " 'replaying',\n",
       " 'sometimes',\n",
       " 'gives',\n",
       " 'Upper-class',\n",
       " 'tributes',\n",
       " 'hometowns',\n",
       " 'media',\n",
       " 'Nights',\n",
       " 'two-way',\n",
       " 'returned',\n",
       " 'winner',\n",
       " 'seemed',\n",
       " 'That',\n",
       " 'go',\n",
       " 'Suspicions',\n",
       " 'However',\n",
       " 'laughs',\n",
       " 'panders',\n",
       " 'anniversary',\n",
       " 'moment',\n",
       " 'four',\n",
       " 'Dubai',\n",
       " 'stern',\n",
       " 'prepared',\n",
       " 'anywhere',\n",
       " 'minimalists',\n",
       " 'something',\n",
       " 'sensuality',\n",
       " 'whether',\n",
       " 'fine',\n",
       " 'eccentric',\n",
       " 'Islam',\n",
       " 'want',\n",
       " 'permitted',\n",
       " 'many',\n",
       " 'recounting',\n",
       " 'Geographic',\n",
       " 'Ladakh',\n",
       " 'sweet',\n",
       " 'allure',\n",
       " 'fully',\n",
       " 'spend',\n",
       " 'India',\n",
       " 'monk',\n",
       " 'lingering',\n",
       " 'make',\n",
       " 'places',\n",
       " 'bubble',\n",
       " 'exclusivity',\n",
       " 'rebellion—oh',\n",
       " 'examples',\n",
       " 'Toronto',\n",
       " 'afford',\n",
       " 'admiration',\n",
       " 'incumbent',\n",
       " 'keep',\n",
       " 'games',\n",
       " 'editions',\n",
       " 'sigh',\n",
       " 'Thiruvananthapuram',\n",
       " 'seen',\n",
       " '(',\n",
       " 'ground',\n",
       " 'lies',\n",
       " 'feature',\n",
       " 'guided',\n",
       " 'gyrating',\n",
       " 'team',\n",
       " 'connections',\n",
       " 'chaat',\n",
       " 'devout',\n",
       " 'part-endearing',\n",
       " 'graduation',\n",
       " 'Forget',\n",
       " 'decadence',\n",
       " 'renaissance',\n",
       " 'readers',\n",
       " '“',\n",
       " 'open',\n",
       " 'As',\n",
       " 'differed',\n",
       " 'Age-style',\n",
       " 'menu',\n",
       " ')',\n",
       " 'universal',\n",
       " 'mayhem',\n",
       " 'Milan',\n",
       " 'number',\n",
       " 'history',\n",
       " 'Flash',\n",
       " 'also',\n",
       " 'solo',\n",
       " 'everyday',\n",
       " 'satisfied',\n",
       " 'Usain',\n",
       " 'train',\n",
       " 'Kuala',\n",
       " 'author',\n",
       " '1990s',\n",
       " 'Oh',\n",
       " 'towards',\n",
       " 'thank',\n",
       " 'December',\n",
       " 'three',\n",
       " 'Sizing',\n",
       " 'dashed',\n",
       " 'edition',\n",
       " 'someday',\n",
       " 'Olympics',\n",
       " 'past',\n",
       " 'arrived',\n",
       " 'companions',\n",
       " 'exploration',\n",
       " 'Let',\n",
       " 'travel',\n",
       " 'leaning',\n",
       " 'parsed',\n",
       " 'unknown',\n",
       " 'simple',\n",
       " 'others',\n",
       " 'confirmed',\n",
       " 'travellers',\n",
       " 'centrepiece',\n",
       " 'pow-wow.',\n",
       " 'flagbearer',\n",
       " 'pens',\n",
       " 'Unable',\n",
       " 'trudging',\n",
       " 'person',\n",
       " 'Live',\n",
       " 'yeah',\n",
       " 'sense',\n",
       " 'shopping',\n",
       " 'use',\n",
       " 'seems',\n",
       " 'aware',\n",
       " 'Tiffany',\n",
       " 'flirting',\n",
       " 'emerging',\n",
       " 'shots',\n",
       " 'newcomer',\n",
       " 'And',\n",
       " 'sea',\n",
       " 'spell',\n",
       " 'game',\n",
       " 'greatest',\n",
       " 'measure',\n",
       " 'Europe',\n",
       " 'stays',\n",
       " 'time',\n",
       " 'metropolis',\n",
       " 'especially',\n",
       " 'Dinakaran',\n",
       " 'All',\n",
       " 'discredits',\n",
       " 'people',\n",
       " 'reminder',\n",
       " 'London',\n",
       " 'Chantilly',\n",
       " 'Anthony',\n",
       " 'swirling',\n",
       " 'solutions',\n",
       " '’',\n",
       " 'consider',\n",
       " 'gearhead',\n",
       " 'Bewildering',\n",
       " 'Read',\n",
       " 'live',\n",
       " 'bitter',\n",
       " 'Vaishali',\n",
       " 'aspire',\n",
       " 'tales',\n",
       " 'Chowpatty',\n",
       " 'anxiety',\n",
       " 'genuinely',\n",
       " 'walks',\n",
       " '!',\n",
       " 'test',\n",
       " 'fun',\n",
       " 'front',\n",
       " 'first',\n",
       " 'China',\n",
       " 'revelries',\n",
       " 'tiffs',\n",
       " 'really',\n",
       " 'dazed',\n",
       " 'Turku',\n",
       " 'another',\n",
       " 'esteem',\n",
       " 'Mysore',\n",
       " 'feel',\n",
       " 'cruise',\n",
       " '2',\n",
       " 'descriptions',\n",
       " 'come',\n",
       " 'days',\n",
       " 'bite',\n",
       " 'Spotting',\n",
       " 'proud',\n",
       " 'account',\n",
       " 'privy',\n",
       " 'surprising',\n",
       " 'paeans',\n",
       " 'owner',\n",
       " 'options',\n",
       " 'riveted',\n",
       " 'independent',\n",
       " 'myriad',\n",
       " 'backpack',\n",
       " 'New',\n",
       " 'wine',\n",
       " 'abroad',\n",
       " 'nightclub',\n",
       " 'adventurous',\n",
       " 'VT',\n",
       " 'Victoria',\n",
       " 'never-ending',\n",
       " 'elite',\n",
       " 'new',\n",
       " 'dramatic',\n",
       " 'years',\n",
       " 'MotorcycleDiaries.',\n",
       " 'simply',\n",
       " 'meal',\n",
       " 'cafés',\n",
       " 'friend',\n",
       " 'Farley',\n",
       " 'fall',\n",
       " 'amends',\n",
       " 'particularly',\n",
       " 'relationship',\n",
       " 'steak',\n",
       " 'unpack',\n",
       " 'billionaire',\n",
       " 'coming',\n",
       " 'final',\n",
       " 'ever',\n",
       " 'comes',\n",
       " 'filling',\n",
       " 'domestic',\n",
       " 'beauty',\n",
       " 'Writer',\n",
       " 'Extravagance',\n",
       " 'us',\n",
       " 'along',\n",
       " 'inimitable',\n",
       " 'descriptors',\n",
       " '.',\n",
       " 'think',\n",
       " 'journey',\n",
       " 'flush',\n",
       " 'context',\n",
       " 'dream',\n",
       " 'better',\n",
       " 'pristine',\n",
       " 'Those',\n",
       " 'Atala',\n",
       " 'several',\n",
       " 'Bauhaus',\n",
       " 'granted',\n",
       " 'Libya',\n",
       " 'maestros',\n",
       " 'blame',\n",
       " 'harp',\n",
       " 'Delhi',\n",
       " 'forays',\n",
       " 'Albert',\n",
       " 'strong',\n",
       " 'Bombay',\n",
       " 'Botswana',\n",
       " 'well',\n",
       " 'incoming',\n",
       " 'faraway',\n",
       " 'rephrase',\n",
       " 'unpretentious',\n",
       " 'fare',\n",
       " 'rest',\n",
       " 'desi',\n",
       " 'Bangladesh',\n",
       " 'experienced',\n",
       " 'Hampi',\n",
       " 'immune',\n",
       " 'Tel',\n",
       " 'discovered',\n",
       " 'Enchanting',\n",
       " 'truth',\n",
       " 'explore',\n",
       " 'over.',\n",
       " 'traps',\n",
       " 'cocktail',\n",
       " 'dominated',\n",
       " 'A',\n",
       " 'changed',\n",
       " 'grand',\n",
       " 'finest',\n",
       " 'warmed',\n",
       " 'sayings',\n",
       " 'millions',\n",
       " 'Hudson',\n",
       " 'drool-worthy',\n",
       " 'slogging',\n",
       " 'If',\n",
       " 'By',\n",
       " 'relocating',\n",
       " 'respond',\n",
       " 'vibrancy',\n",
       " 'join',\n",
       " 'trying',\n",
       " 'pesky',\n",
       " 'roundup',\n",
       " 'smiles',\n",
       " 'straight',\n",
       " 'Times',\n",
       " 'countryside',\n",
       " 'English',\n",
       " 'Anniversary',\n",
       " 'ballroom',\n",
       " 'Ghoda',\n",
       " 'Chinmai',\n",
       " 'France',\n",
       " 'Goa',\n",
       " 'pure',\n",
       " 'unrepentant',\n",
       " 'making',\n",
       " 'Arre',\n",
       " 'smacked',\n",
       " 'year',\n",
       " 'reach',\n",
       " 'destination',\n",
       " 'one…',\n",
       " 'kind',\n",
       " 'unforgettable',\n",
       " 'overflowing',\n",
       " 'Wealth',\n",
       " 'Hajela',\n",
       " 'empty',\n",
       " 'handful',\n",
       " 'Told',\n",
       " 'get',\n",
       " 'world',\n",
       " 'requested',\n",
       " 'five',\n",
       " 'purse-strings',\n",
       " 'wrote',\n",
       " 'nothing—floating',\n",
       " 'shrines',\n",
       " 'September',\n",
       " 'road',\n",
       " 'Terminus',\n",
       " 'access',\n",
       " 'without',\n",
       " 'How',\n",
       " 'heart',\n",
       " 'present-day',\n",
       " 'Asia',\n",
       " 'refined',\n",
       " 'histories',\n",
       " 'scanned',\n",
       " 'one',\n",
       " 'great',\n",
       " 'Where',\n",
       " 'studious',\n",
       " 'held',\n",
       " 'glowing',\n",
       " 'snobs',\n",
       " 'slight',\n",
       " 'every',\n",
       " 'skin',\n",
       " 'become',\n",
       " 'jewels',\n",
       " 'trash',\n",
       " 'joints',\n",
       " 'pleasures',\n",
       " 'royalty',\n",
       " 'Zacharias',\n",
       " 'chronicle',\n",
       " 'impression',\n",
       " 'far',\n",
       " 'irresistible',\n",
       " 'schooling',\n",
       " 'Belfast',\n",
       " 'fruit-laden',\n",
       " 'lay',\n",
       " 'chalkboard',\n",
       " 'seek',\n",
       " 'achievement',\n",
       " 'gnawing',\n",
       " 'curries',\n",
       " 'global',\n",
       " 'local',\n",
       " 'evokes',\n",
       " 'guidebook-toting',\n",
       " 'The',\n",
       " 'His',\n",
       " 'hardly',\n",
       " 'mystical',\n",
       " 'cosy',\n",
       " 'ephemeral',\n",
       " 'reminded',\n",
       " 'crowded',\n",
       " 'To',\n",
       " 'Grecian',\n",
       " 'wrong',\n",
       " 'dispatches',\n",
       " '—the',\n",
       " 'head',\n",
       " 'Japan',\n",
       " 'palace',\n",
       " 'land',\n",
       " 'Taylor',\n",
       " 'muster',\n",
       " 'lowdown',\n",
       " 'Luxury',\n",
       " 'Nobel',\n",
       " 'even',\n",
       " 'Yorkers',\n",
       " 'pride',\n",
       " 'side',\n",
       " 'Mumbai',\n",
       " 'Indians',\n",
       " 'heritage',\n",
       " 'loses',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list of distinct words\n",
    "distinct_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bag of words representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          words  d1  d2  d3  d4  d5\n",
      "0      server—a   0   0   1   0   0\n",
      "1          meat   0   0   1   0   0\n",
      "2             ;   0   0   1   2   1\n",
      "3           buy   0   1   0   0   0\n",
      "4          work   0   0   0   0   1\n",
      "..          ...  ..  ..  ..  ..  ..\n",
      "95  interesting   0   0   1   0   0\n",
      "96        gates   0   0   0   0   1\n",
      "97      manager   0   0   1   0   0\n",
      "98    Traveller   1   0   0   0   0\n",
      "99     drinking   0   1   0   0   0\n",
      "\n",
      "[100 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def Bag_of_words(word_list):\n",
    "    word_l = []\n",
    "    for word in distinct_words:\n",
    "        if (word in word_list) == True:\n",
    "            word_l.append(word_list.count(word))\n",
    "        else:\n",
    "            word_l.append(0)\n",
    "        \n",
    "    return word_l\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"words\"] = distinct_words\n",
    "df[\"d1\"] = Bag_of_words(d1)\n",
    "df[\"d2\"] = Bag_of_words(d2)\n",
    "df[\"d3\"] = Bag_of_words(d3)\n",
    "df[\"d4\"] = Bag_of_words(d4)\n",
    "df[\"d5\"] = Bag_of_words(d5)\n",
    "\n",
    "    \n",
    "print(df.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           words   d1   d2        d3        d4   d5\n",
      "0       server—a  0.0  0.0  1.000000  0.000000  0.0\n",
      "1           meat  0.0  0.0  1.000000  0.000000  0.0\n",
      "2              ;  0.0  0.0  1.000000  1.526589  1.0\n",
      "3            buy  0.0  1.0  0.000000  0.000000  0.0\n",
      "4           work  0.0  0.0  0.000000  0.000000  1.0\n",
      "...          ...  ...  ...       ...       ...  ...\n",
      "1062        Bolt  0.0  0.0  0.000000  1.000000  0.0\n",
      "1063     pretend  0.0  0.0  0.000000  1.000000  0.0\n",
      "1064        real  1.0  1.0  0.000000  0.000000  0.0\n",
      "1065        food  0.0  1.0  1.959135  0.000000  1.0\n",
      "1066  pugilistic  0.0  0.0  0.000000  1.000000  0.0\n",
      "\n",
      "[1067 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def TF(word_list):\n",
    "    word_l = []\n",
    "    for word in distinct_words:\n",
    "        if (word in word_list) == True:\n",
    "            word_l.append(1+math.log(1+math.log(word_list.count(word))))\n",
    "        else:\n",
    "            word_l.append(0)\n",
    "        \n",
    "    return word_l\n",
    "\n",
    "tf = pd.DataFrame()\n",
    "tf[\"words\"] = distinct_words\n",
    "tf[\"d1\"] = TF(d1)\n",
    "tf[\"d2\"] = TF(d2)\n",
    "tf[\"d3\"] = TF(d3)\n",
    "tf[\"d4\"] = TF(d4)\n",
    "tf[\"d5\"] = TF(d5)\n",
    "    \n",
    "print(tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            word  relevance\n",
      "0       server—a   1.791759\n",
      "1           meat   1.791759\n",
      "2              ;   0.980829\n",
      "3            buy   1.791759\n",
      "4           work   1.791759\n",
      "...          ...        ...\n",
      "1062        Bolt   1.791759\n",
      "1063     pretend   1.791759\n",
      "1064        real   1.252763\n",
      "1065        food   0.980829\n",
      "1066  pugilistic   1.791759\n",
      "\n",
      "[1067 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "idf = pd.DataFrame()\n",
    "\n",
    "def IDF():\n",
    "    l = []\n",
    "    D = [d1,d2,d3,d4,d5]\n",
    "    for i in distinct_words:\n",
    "        d = 0\n",
    "        for j in D:\n",
    "            if i in j:\n",
    "                d+=1\n",
    "                \n",
    "        l.append(math.log(1+5/d))\n",
    "        \n",
    "    return l\n",
    "        \n",
    "idf[\"word\"] = distinct_words\n",
    "idf[\"relevance\"] = IDF()\n",
    "\n",
    "        \n",
    "print(idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           words        d1        d2        d3        d4        d5\n",
      "0       server—a  0.000000  0.000000  1.791759  0.000000  0.000000\n",
      "1           meat  0.000000  0.000000  1.791759  0.000000  0.000000\n",
      "2              ;  0.000000  0.000000  0.980829  1.497323  0.980829\n",
      "3            buy  0.000000  1.791759  0.000000  0.000000  0.000000\n",
      "4           work  0.000000  0.000000  0.000000  0.000000  1.791759\n",
      "...          ...       ...       ...       ...       ...       ...\n",
      "1062        Bolt  0.000000  0.000000  0.000000  1.791759  0.000000\n",
      "1063     pretend  0.000000  0.000000  0.000000  1.791759  0.000000\n",
      "1064        real  1.252763  1.252763  0.000000  0.000000  0.000000\n",
      "1065        food  0.000000  0.980829  1.921577  0.000000  0.980829\n",
      "1066  pugilistic  0.000000  0.000000  0.000000  1.791759  0.000000\n",
      "\n",
      "[1067 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "tfidf = pd.DataFrame()\n",
    "tfidf[\"words\"] = distinct_words\n",
    "\n",
    "n1 = np.array(tf.d1)\n",
    "n2 = np.array(tf.d2)\n",
    "n3 = np.array(tf.d3)\n",
    "n4 = np.array(tf.d4)\n",
    "n5 = np.array(tf.d5)\n",
    "x = np.array(idf.relevance)\n",
    "\n",
    "tfidf[\"d1\"] = n1*x\n",
    "tfidf[\"d2\"] = n2*x\n",
    "tfidf[\"d3\"] = n3*x\n",
    "tfidf[\"d4\"] = n4*x\n",
    "tfidf[\"d5\"] = n5*x\n",
    "\n",
    "print(tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           words        d1        d2        d3        d4        d5\n",
      "0       server—a  0.000000  0.000000  0.001679  0.000000  0.000000\n",
      "1           meat  0.000000  0.000000  0.001679  0.000000  0.000000\n",
      "2              ;  0.000000  0.000000  0.000919  0.001403  0.000919\n",
      "3            buy  0.000000  0.001679  0.000000  0.000000  0.000000\n",
      "4           work  0.000000  0.000000  0.000000  0.000000  0.001679\n",
      "...          ...       ...       ...       ...       ...       ...\n",
      "1062        Bolt  0.000000  0.000000  0.000000  0.001679  0.000000\n",
      "1063     pretend  0.000000  0.000000  0.000000  0.001679  0.000000\n",
      "1064        real  0.001174  0.001174  0.000000  0.000000  0.000000\n",
      "1065        food  0.000000  0.000919  0.001801  0.000000  0.000919\n",
      "1066  pugilistic  0.000000  0.000000  0.000000  0.001679  0.000000\n",
      "\n",
      "[1067 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#normalized tf-idf for docs\n",
    "tfidf.d1/=len(distinct_words)\n",
    "tfidf.d2/=len(distinct_words)\n",
    "tfidf.d3/=len(distinct_words)\n",
    "tfidf.d4/=len(distinct_words)\n",
    "tfidf.d5/=len(distinct_words)\n",
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'d1': 0.0698268963, 'd2': 0.0472304297, 'd3': 0.0524115398, 'd4': 0.0783768587}\n"
     ]
    }
   ],
   "source": [
    "#cosine-similarity\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "cs = {}\n",
    "q = 0\n",
    "for i in np.array(tfidf.d5):\n",
    "    q+=(i**2)\n",
    "    \n",
    "# print(q)\n",
    "\n",
    "def cosine_sim(doc):\n",
    "    d = 0\n",
    "    for i in doc:\n",
    "        d+=(i**2) \n",
    "        \n",
    "#     print(d)\n",
    "    a = doc.dot(np.array(tfidf.d5))\n",
    "#     print(a)\n",
    "#     return (a/(math.sqrt(q*d)))\n",
    "    return('{0:.10f}'.format((a/(math.sqrt(q*d)))))\n",
    "\n",
    "cs[\"d1\"] = float(cosine_sim(np.array(tfidf.d1)))\n",
    "cs[\"d2\"] = float(cosine_sim(np.array(tfidf.d2)))\n",
    "cs[\"d3\"] = float(cosine_sim(np.array(tfidf.d3)))\n",
    "cs[\"d4\"] = float(cosine_sim(np.array(tfidf.d4)))\n",
    "print(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "1\n",
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#document ranking\n",
    "def rank_doc(array):\n",
    "    l = array.copy()\n",
    "    valid = True\n",
    "    while valid:\n",
    "#         print(l)\n",
    "        if(len(np.where(array == max(l))[0]) > 1):\n",
    "            for i in range(len(np.where(array == max(l))[0])):\n",
    "                print((np.where(array == max(l))[0][i]+1),)\n",
    "            l = np.delete(l,np.where(l == max(l)),0)\n",
    "        else:\n",
    "            print(np.where(array == max(l))[0][0]+1)\n",
    "            l = np.delete(l,np.where(l == max(l))[0],0)\n",
    "            \n",
    "        if(len(l) == 0):\n",
    "            valid = False\n",
    "            \n",
    "\n",
    "rank_doc(np.array(list(cs.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eucledian Distance and Document Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'d1': 0.0342566834, 'd2': 0.0340484218, 'd3': 0.0357740865, 'd4': 0.0338834713}\n",
      "[0.0342566834, 0.0340484218, 0.0357740865, 0.0338834713]\n",
      "4\n",
      "2\n",
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "ed = {}\n",
    "def euc_d(doc,query):\n",
    "    e = 0\n",
    "    for i in range(len(doc)):\n",
    "        e+=(doc[i] - query[i])**2\n",
    "        \n",
    "    return ('{0:.10f}'.format(math.sqrt(e)))\n",
    "        \n",
    "ed[\"d1\"] = float(euc_d(np.array(tfidf.d1), np.array(tfidf.d5)))\n",
    "ed[\"d2\"] = float(euc_d(np.array(tfidf.d2), np.array(tfidf.d5)))\n",
    "ed[\"d3\"] = float(euc_d(np.array(tfidf.d3), np.array(tfidf.d5)))\n",
    "ed[\"d4\"] = float(euc_d(np.array(tfidf.d4), np.array(tfidf.d5)))\n",
    "print(ed)\n",
    "print(list(ed.values()))\n",
    "\n",
    "def rank_doc(array):\n",
    "    l = array.copy()\n",
    "    valid = True\n",
    "    while valid:\n",
    "        if(len(np.where(array == min(l))[0]) > 1):\n",
    "            for i in range(len(np.where(array == min(l))[0])):\n",
    "                print((np.where(array == min(l))[0][i]+1),)\n",
    "            l = np.delete(l,np.where(l == min(l)),0)\n",
    "        else:\n",
    "            print(np.where(array == min(l))[0][0]+1)\n",
    "            l = np.delete(l,np.where(l == min(l))[0],0)\n",
    "            \n",
    "        if(len(l) == 0):\n",
    "            valid = False\n",
    "\n",
    "            \n",
    "\n",
    "rank_doc(np.array(list(ed.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Note - we see that after computing the cosine similarity and Eucledian distance between the sample article and the 4 articles given to us in the form of the corpus, the similarity is almost negligible.\n",
    "Hence it is safe to assume that the articles she writes are original and we can hire her for our publication.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
